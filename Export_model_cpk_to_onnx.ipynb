{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eugeniusz-raspberrypi/Export_model_cpk_to_onnx/blob/main/Export_model_cpk_to_onnx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "0. Instalacja zależności (wykonaj raz)"
      ],
      "metadata": {
        "id": "ulTkpdiGQjI4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y37QtlLmPuqT"
      },
      "outputs": [],
      "source": [
        "# KOMÓRKA 0 – Instalacja zależności (wykonaj raz)\n",
        "!pip install -q piper-tts onnx onnxruntime torch soundfile numpy tqdm\n",
        "# (piper-tts już zawiera wszystkie potrzebne części train/*)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Wgranie Twojego modelu .cpk i config.json"
      ],
      "metadata": {
        "id": "tRWDRJUpQrfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KOMÓRKA 1 – Wgranie Twojego modelu .cpk i config.json\n",
        "from google.colab import files\n",
        "uploaded = files.upload()   # w tym miejscu wczytaj swój plik .cpk i (opcjonalnie) config.json"
      ],
      "metadata": {
        "id": "aN5lcQRZQs3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Sam skrypt (wersja Colab-friendly) – wystarczy uruchomić raz i wpisać nazwy plików"
      ],
      "metadata": {
        "id": "J_MRPygaQ1cQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KOMÓRKA 2 – Sam skrypt (wersja Colab-friendly) – wystarczy uruchomić raz i wpisać nazwy plików\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "from piper.train.checkpoint import load_checkpoint\n",
        "from piper.voice import PiperVoice\n",
        "\n",
        "# ——— WPISZ TUTAJ NAZWY SWOICH PLIKÓW ———\n",
        "cpk_file     = \"moj_glos.cpk\"          # ← zmień na nazwę Twojego .cpk\n",
        "config_file  = \"config.json\"           # ← jeśli masz osobny config.json, w przeciwnym razie zostaw\n",
        "output_name  = \"moj_glos_polski\"       # ← jak ma się nazywać finalny model (bez rozszerzenia)\n",
        "\n",
        "# Automatyczne wykrycie config.json jeśli nie podałeś\n",
        "if not os.path.exists(config_file):\n",
        "    potential = os.path.join(os.path.dirname(cpk_file), \"config.json\")\n",
        "    if os.path.exists(potential):\n",
        "        config_file = potential\n",
        "\n",
        "# ——— Reszta skryptu (nie ruszaj) ———\n",
        "print(f\"Używany .cpk: {cpk_file}\")\n",
        "print(f\"Używany config: {config_file}\")\n",
        "\n",
        "model_dir = os.path.dirname(cpk_file) if os.path.dirname(cpk_file) else \".\"\n",
        "model = load_checkpoint(cpk_path=cpk_file, model_dir=model_dir, use_cuda=False)\n",
        "voice = PiperVoice(model, config_path=config_file)\n",
        "\n",
        "voice.model.eval()\n",
        "print(\"Eksportowanie do ONNX...\")\n",
        "\n",
        "dummy_text = \"To jest testowy tekst do wygenerowania wejścia.\"\n",
        "synthesize_input = voice.create_synthesize_input(dummy_text)\n",
        "\n",
        "input_ids = torch.tensor(synthesize_input[\"input_ids\"], dtype=torch.long).unsqueeze(0)\n",
        "scales = torch.tensor([1.0, 0.667, 0.8], dtype=torch.float32)\n",
        "\n",
        "export_kwargs = {\"input_ids\": input_ids, \"scales\": scales}\n",
        "input_names = [\"input_ids\", \"scales\"]\n",
        "\n",
        "if voice.config.num_speakers > 1:\n",
        "    speaker_id = torch.tensor([0], dtype=torch.long)\n",
        "    export_kwargs[\"speaker_id\"] = speaker_id\n",
        "    input_names.append(\"speaker_id\")\n",
        "\n",
        "onnx_path = f\"{output_name}.onnx\"\n",
        "torch.onnx.export(\n",
        "    voice.model,\n",
        "    args=tuple(export_kwargs.values()),\n",
        "    f=onnx_path,\n",
        "    export_params=True,\n",
        "    opset_version=17,\n",
        "    do_constant_folding=True,\n",
        "    input_names=input_names,\n",
        "    output_names=[\"audio\"],\n",
        "    dynamic_axes={\"input_ids\": {0: \"batch\", 1: \"sequence\"}},\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "# Generowanie .onnx.json (metadata)\n",
        "json_path = f\"{output_name}.onnx.json\"\n",
        "with open(config_file) as f:\n",
        "    config_data = json.load(f)\n",
        "\n",
        "# Dodanie brakujących pól inferencji (standard Piper)\n",
        "config_data.setdefault(\"inference\", {\n",
        "    \"noise_scale\": 0.667,\n",
        "    \"length_scale\": 1.0,\n",
        "    \"noise_w\": 0.8\n",
        "})\n",
        "config_data[\"name\"] = output_name\n",
        "config_data[\"key\"]  = output_name\n",
        "\n",
        "with open(json_path, \"w\") as f:\n",
        "    json.dump(config_data, f, indent=4)\n",
        "\n",
        "print(\"GOTOWE!\")\n",
        "print(f\" • {onnx_path}  → {os.path.getsize(onnx_path)/1024/1024:.1f} MB\")\n",
        "print(f\" • {json_path}\")\n",
        "\n",
        "# Pobieranie na swój komputer\n",
        "from google.colab import files\n",
        "files.download(onnx_path)\n",
        "files.download(json_path)"
      ],
      "metadata": {
        "id": "w-0x1IWPQ7UB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. (opcjonalna) szybki test czy model działa"
      ],
      "metadata": {
        "id": "k_qVUXtoRArT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KOMÓRKA 3 (opcjonalna) – szybki test czy model działa\n",
        "\n",
        "# Zainstaluj binarkę piper (najnowszą)\n",
        "!wget -q https://github.com/rhasspy/piper/releases/download/v1.2.0/piper_amd64.tar.gz\n",
        "!tar -xf piper_amd64.tar.gz\n",
        "!chmod +x piper/piper\n",
        "\n",
        "# Test\n",
        "!./piper/piper --model {output_name}.onnx --output_file test.wav --text \"Cześć, to jest mój sklonowany głos w języku polskim. Działa idealnie!\"\n",
        "files.download(\"test.wav\")"
      ],
      "metadata": {
        "id": "L9ARM5C9RDZ_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}